#!/usr/bin/env -S uv run --script
# /// script
# requires-python = ">=3.10"
# dependencies = [
#   "openai-whisper==20250625",
#   "torch==2.10.0",
#   "imageio-ffmpeg==0.6.0",
# ]
# ///
"""audio-transcribe: 使用 Whisper + ffmpeg 转写音频文件
Usage: audio-transcribe <audio_file> [--model MODEL] [--language LANG]
Output: JSON with transcription, segments, and metadata

Requires: ffmpeg (auto-downloaded via imageio-ffmpeg when using uv) or a system ffmpeg
"""

import argparse
import hashlib
import json
import os
import shutil
import sys
import time
from pathlib import Path

def ensure_ffmpeg() -> tuple[str | None, str | None]:
    env_binary = os.environ.get("FFMPEG_BINARY")
    if env_binary and Path(env_binary).exists():
        os.environ["PATH"] = f"{Path(env_binary).parent}:{os.environ.get('PATH', '')}"
        return env_binary, None

    existing = shutil.which("ffmpeg")
    if existing:
        return existing, None

    try:
        import imageio_ffmpeg

        ffmpeg_path = imageio_ffmpeg.get_ffmpeg_exe()
        if ffmpeg_path and Path(ffmpeg_path).exists():
            os.environ["FFMPEG_BINARY"] = ffmpeg_path
            os.environ["PATH"] = f"{Path(ffmpeg_path).parent}:{os.environ.get('PATH', '')}"
            return ffmpeg_path, None
    except Exception as err:
        return None, str(err)

    return None, None


ffmpeg_path, ffmpeg_error = ensure_ffmpeg()
if not ffmpeg_path:
    error_payload = {
        "error": "ffmpeg not found. Install ffmpeg or use uv to auto-download it.",
        "install": {
            "macos": "brew install ffmpeg",
            "ubuntu": "sudo apt update && sudo apt install ffmpeg",
            "arch": "sudo pacman -S ffmpeg",
        },
    }
    if ffmpeg_error:
        error_payload["detail"] = ffmpeg_error
    print(json.dumps(error_payload, ensure_ascii=False, indent=2))
    sys.exit(1)


def resolve_whisper_site_packages() -> Path | None:
    site_override = os.environ.get("WHISPER_SITE_PACKAGES") or os.environ.get(
        "AUDIO_PIPELINE_WHISPER_SITE_PACKAGES"
    )
    if site_override:
        return Path(site_override)

    venv = os.environ.get("WHISPER_VENV") or os.environ.get("AUDIO_PIPELINE_WHISPER_VENV")
    if venv:
        py_version = os.environ.get("WHISPER_PYTHON_VERSION") or (
            f"{sys.version_info.major}.{sys.version_info.minor}"
        )
        candidates = [
            Path(venv) / "lib" / f"python{py_version}" / "site-packages",
            Path(venv) / "lib" / "python3" / "site-packages",
        ]
        for candidate in candidates:
            if candidate.exists():
                return candidate
    return None


def load_whisper_modules():
    try:
        import torch
        import whisper

        return torch, whisper
    except ModuleNotFoundError:
        site_packages = resolve_whisper_site_packages()
        if site_packages and site_packages.exists():
            sys.path.insert(0, str(site_packages))
            import torch
            import whisper

            return torch, whisper

        print(
            json.dumps(
                {
                    "error": "whisper module not found",
                    "hint": "Install uv and run this script, or install openai-whisper+torch in the current env",
                },
                ensure_ascii=False,
            )
        )
        sys.exit(1)


torch, whisper = load_whisper_modules()


def resolve_device(requested: str | None) -> str:
    has_cuda = torch.cuda.is_available()
    has_mps = bool(getattr(torch.backends, "mps", None)) and torch.backends.mps.is_available()

    if requested:
        if requested == "cuda" and not has_cuda:
            raise RuntimeError("CUDA requested but torch.cuda.is_available() is False")
        if requested == "mps" and not has_mps:
            raise RuntimeError("MPS requested but torch.backends.mps.is_available() is False")
        return requested

    if has_cuda:
        return "cuda"
    if has_mps:
        return "mps"
    return "cpu"


SUPPORTED_EXTS = {".mp3", ".wav", ".m4a", ".ogg", ".flac", ".webm", ".mp4"}


def get_file_hash(filepath: Path) -> str:
    """计算文件内容的 SHA256 hash（前 1MB）"""
    sha256 = hashlib.sha256()
    with open(filepath, "rb") as f:
        sha256.update(f.read(1024 * 1024))
    return sha256.hexdigest()[:16]


def main():
    parser = argparse.ArgumentParser(description="Transcribe audio using Whisper")
    parser.add_argument("audio_file", help="Path to audio file")
    parser.add_argument(
        "--model",
        default=os.environ.get("WHISPER_MODEL", "base"),
        help="Whisper model name (tiny, base, small, medium, large)",
    )
    parser.add_argument("--language", default="zh", help="Language code (default: zh)")
    parser.add_argument(
        "--device",
        choices=["cpu", "cuda", "mps"],
        help="Device override (cpu/cuda/mps)",
    )
    parser.add_argument("--output-dir", type=Path, help="Output directory for transcription files")

    args = parser.parse_args()

    audio_path = Path(args.audio_file).expanduser().resolve()
    if not audio_path.exists():
        print(json.dumps({"error": f"File not found: {audio_path}"}, ensure_ascii=False))
        sys.exit(1)

    if audio_path.suffix.lower() not in SUPPORTED_EXTS:
        print(json.dumps({"error": f"Unsupported format: {audio_path.suffix}"}, ensure_ascii=False))
        sys.exit(1)

    try:
        device = resolve_device(args.device)
    except RuntimeError as err:
        print(json.dumps({"error": str(err)}, ensure_ascii=False))
        sys.exit(1)

    try:
        cache_dir = Path(
            os.environ.get(
                "WHISPER_CACHE_DIR",
                os.environ.get("AUDIO_PIPELINE_CACHE_DIR", str(Path.home() / ".loong" / "cache" / "whisper")),
            )
        )
        cache_dir.mkdir(parents=True, exist_ok=True)

        print(f"Loading model '{args.model}' on {device}...", file=sys.stderr, flush=True)
        model = whisper.load_model(args.model, device=device, download_root=str(cache_dir))

        start_time = time.time()
        result = model.transcribe(str(audio_path), language=args.language, verbose=False)
        elapsed = time.time() - start_time

        file_hash = get_file_hash(audio_path)

        output = {
            "hash": file_hash,
            "filename": str(audio_path),
            "text": result.get("text", "").strip(),
            "language": result.get("language", args.language),
            "segments": [
                {
                    "start": seg.get("start", 0),
                    "end": seg.get("end", 0),
                    "text": seg.get("text", "").strip(),
                }
                for seg in result.get("segments", [])
            ],
            "model": args.model,
            "device": device,
            "duration": elapsed,
        }

        if args.output_dir:
            output_dir = Path(args.output_dir).expanduser().resolve()
            output_dir.mkdir(parents=True, exist_ok=True)

            trans_file = output_dir / f"{file_hash}.json"
            with open(trans_file, "w", encoding="utf-8") as f:
                json.dump(output, f, ensure_ascii=False, indent=2)

            text_file = output_dir / f"{file_hash}.txt"
            with open(text_file, "w", encoding="utf-8") as f:
                f.write(output["text"])

            output["transcription_file"] = str(trans_file)
            output["text_file"] = str(text_file)

        print(json.dumps(output, ensure_ascii=False))

    except Exception as e:
        print(json.dumps({"error": str(e)}, ensure_ascii=False))
        sys.exit(1)


if __name__ == "__main__":
    raise SystemExit(main())
